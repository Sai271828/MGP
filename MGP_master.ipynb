{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahIsZjjNp1te"
      },
      "source": [
        "# Math genealogy project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RV2npq46AcA"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) 2023\n",
        "Authors: Venkata Sai Narayana Bavisetty, Karthik Vasu\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEDB05nMp9IS"
      },
      "source": [
        "In this notebook, we outline the process of downloading Math genealogy data and coordinates for different universities. We will conclude by analyzing the data and providing explanations for some of our findings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGXIVaVvqf4h"
      },
      "source": [
        "# Downloading math genealogy data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd56xQltq0Nf"
      },
      "source": [
        "In this notebook, we outline the process of downloading Math genealogy data and coordinates for different universities. We will conclude by analyzing the data and providing explanations for some of our findings.\n",
        "\n",
        "We utilized the [MGP API](https://mathgenealogy.org:8000/api/v2/MGP/) for data retrieval. Below is the script code for downloading the data. While the script is primarily sourced from the [MGP website](https://mathgenealogy.org:8000/login), we made modifications to implement exponential backoff in case of request failures. This adaptation is crucial for successfully downloading the entire dataset in one go.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp9xEZeR3IV7"
      },
      "source": [
        "\n",
        "We download data in batches of $100$ IDs. Although the website indicates that we can download $10,000$ IDs at once, we encountered difficulties when attempting to do so in batches of $10,000$ or even $1,000$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjya_gFbtv8p",
        "outputId": "d075c3fa-0326-4f80-cacf-2fa40ecb5070"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n"
          ]
        }
      ],
      "source": [
        "#pip install backoff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4NM6ShGfPSLu"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import sys\n",
        "#import backoff\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzGYypy7qzih"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Nov 24 18:57:07 2023\n",
        "\n",
        "@author: venka\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "PROTOCOL = \"https\"\n",
        "HOSTNAME = \"mathgenealogy.org\"\n",
        "PORT = \"8000\"\n",
        "\n",
        "# Function to prompt on the console for the user's\n",
        "# email address and password to use to log in to\n",
        "# the MGP API. Password is not shown on console\n",
        "# while the user types it.\n",
        "def getlogin():\n",
        "    print(\"Enter email used for MGP authentication:\",end=\" \",file=sys.stderr)\n",
        "    #email = input()\n",
        "    #password = getpass()\n",
        "    return {'email': \"vb8@illinois.edu\", 'password': \"2FAeinaitrelo!\"}\n",
        "\n",
        "# Function to log in to the MGP API and get a JWT for authentication.\n",
        "# authdata is a dict with key email set to the user's email address\n",
        "# and key password set to the user's password.\n",
        "# If login is successful, returns a JSON object with key token set\n",
        "# to the JWT.\n",
        "# If login is unsuccessful, raises RuntimeError.\n",
        "def login(authdata):\n",
        "    r = requests.post(f\"{PROTOCOL}://{HOSTNAME}:{PORT}/login\", authdata)\n",
        "    if r.ok:\n",
        "        r.close()\n",
        "        return r.json()\n",
        "    else:\n",
        "        r.close()\n",
        "        raise RuntimeError(\"Failed to authenticate\")\n",
        "\n",
        "# Function to do a query against the MGP API. Returns a string with\n",
        "# the query result if the query was successfully executed. Raises\n",
        "# RuntimeError if there is an error.\n",
        "\n",
        "# endpoint is a string (beginning with /) such as \"/api/v2/MGP/acad\"\n",
        "# referring to an API endpoint\n",
        "\n",
        "# token is a dict with key token containing a JWT.\n",
        "# The return value from login() is the best way to get this.\n",
        "\n",
        "# params is a dict structured to contain the GET parameters.\n",
        "# For example, if quering /api/v2/MGP/acad, params could be\n",
        "# {'id': '1969'}.\n",
        "@backoff.on_exception(backoff.expo, (requests.exceptions.Timeout,requests.exceptions.RequestException), max_tries= 8)\n",
        "def doquery(endpoint,token, params):\n",
        "    headers = {'x-access-token': token['token']}\n",
        "    r = requests.get(f\"{PROTOCOL}://{HOSTNAME}:{PORT}{endpoint}\",headers = headers, params = params)\n",
        "    if r.ok:\n",
        "        r.close()\n",
        "        return r.text\n",
        "\n",
        "\n",
        "\n",
        "# User modifications can be made here in this portion of the script.\n",
        "# Alternatively, import the functions above into your own python\n",
        "# script and write code similar to what is given here as the example.\n",
        "if __name__ == '__main__':\n",
        "\n",
        "\n",
        "\n",
        "    # Example for results coming back as JSON\n",
        "\n",
        "    #for id in range(31):\n",
        "    for id in range(3100):\n",
        "        authdata = getlogin()\n",
        "        token = login(authdata)\n",
        "\n",
        "\n",
        "        querydata = {'start': id*100, \"stop\":(id+1)*100}\n",
        "        endpoint = '/api/v2/MGP/acad/range'\n",
        "        data = json.loads(doquery(endpoint,token,querydata))\n",
        "        json_file = \"try.json\"\n",
        "\n",
        "        # Save data to a JSON file\n",
        "        with open(json_file, 'a', encoding='utf-8') as jsonfile:\n",
        "            json.dump(data, jsonfile, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Data has been saved to '{json_file}'.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3EbVBQeXpodv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the JSON file\n",
        "with open('C:\\\\Users\\\\karth\\\\Code\\\\MGP\\\\data\\\\MGP_data.json', 'r') as file:\n",
        "    all_data = json.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bNW3E-U90-H5"
      },
      "outputs": [],
      "source": [
        "data=[]\n",
        "\n",
        "school_split_len = []\n",
        "for temp_row in all_data:\n",
        "    row = temp_row['MGP_academic']\n",
        "\n",
        "    try:\n",
        "        school = row['student_data']['degrees'][0]['schools'][0]\n",
        "    except:\n",
        "        school = 'None'\n",
        "\n",
        "    split = school.split(',')\n",
        "    school_split_len.append(len(split))\n",
        "    if len(split)>1:\n",
        "        country = split[-1]\n",
        "    school = split[0]\n",
        "\n",
        "    try:\n",
        "        year = row['student_data']['degrees'][0]['degree_year']\n",
        "    except:\n",
        "        year = 'None'\n",
        "    \n",
        "    try:\n",
        "        subject = int(row['student_data']['degrees'][0]['degree_msc'])\n",
        "    except:\n",
        "        subject = 'None'\n",
        "\n",
        "    new_row = {\n",
        "        'ID':row['ID'],\n",
        "        'family_name':row['family_name'],\n",
        "        'given_name':row['given_name'],\n",
        "        'school':school,\n",
        "        'year':year,\n",
        "        'descendants':row['student_data']['descendants']['descendant_count'],\n",
        "        'country':country,\n",
        "        'subject':subject\n",
        "        }\n",
        "    data.append(new_row)\n",
        "\n",
        "data = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWCFqDsK0-X2"
      },
      "source": [
        "# Downloading the coordinate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcRO626V09fk"
      },
      "outputs": [],
      "source": [
        "def get_coordinates(university_name,use_Bing=False,bing_api_key=None):\n",
        "\n",
        "    # Bing API geocoder\n",
        "    if use_Bing:\n",
        "        geolocator = Bing(api_key=bing_api_key)\n",
        "\n",
        "    # Nominatim geocoder\n",
        "    else:\n",
        "        geolocator = Nominatim(user_agent=\"university_locator\")\n",
        "\n",
        "    university_name_no_filler = remove_fillers(university_name)\n",
        "\n",
        "    try:\n",
        "        # Use the geocode method to get the location information\n",
        "        location = geolocator.geocode(university_name_no_filler)\n",
        "\n",
        "        if location:\n",
        "            # Extract latitude and longitude\n",
        "            latitude, longitude = location.latitude, location.longitude\n",
        "            return [university_name,latitude,longitude]\n",
        "\n",
        "        else:\n",
        "            # if we did not get the location return location in Antartica\n",
        "            return [university_name,-82,135]\n",
        "            #print(f\"Coordinates for {university_name} not found.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        #print(f\"An error occurred: {e}\")\n",
        "        #If there is an error we return None\n",
        "        return [university_name,None,None]\n",
        "\n",
        "def remove_fillers(sentence):\n",
        "\n",
        "    sentence = str(sentence)\n",
        "    # List of filler words\n",
        "    filler_words = ['the', 'of', 'and', 'in', 'to', 'a', 'is', 'that', 'it', 'with', 'as', 'on', 'for', 'at']\n",
        "\n",
        "    # Split the sentence into words\n",
        "    words = sentence.split()\n",
        "\n",
        "    # Remove filler words\n",
        "    filtered_words = [word for word in words if word.lower() not in filler_words]\n",
        "\n",
        "    # Join the remaining words to form the new sentence\n",
        "    new_sentence = ' '.join(filtered_words)\n",
        "\n",
        "    return new_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqEQH7bROyux"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set download_coordinates to True if you want to download the coordinates\n",
        "download_coordinates = False\n",
        "\n",
        "# If you want to use Bing maps API, set use_Bing to True and enter your API key\n",
        "use_Bing = False\n",
        "bing_api_key = None\n",
        "\n",
        "if download_coordinates:\n",
        "\n",
        "    import time\n",
        "\n",
        "    # Using Bing maps API for better performance. This requires a free account and an API key\n",
        "    from geopy.geocoders import Bing\n",
        "\n",
        "    # Alternatively we can use OpenStreetMaps API which is free and open source, but does not perform as well as Bing\n",
        "    from geopy.geocoders import Nominatim\n",
        "\n",
        "    # Get the unique schools\n",
        "    schools = data['school'].unique()\n",
        "\n",
        "    # Loop through the schools and save the recieved coordinates in coord\n",
        "    coords =[]\n",
        "    count = 0\n",
        "    for school in tqdm(schools):\n",
        "        coord = get_coordinates(school,use_Bing=use_Bing,bing_api_key=bing_api_key)\n",
        "        coords.append(coord)\n",
        "        count+=1\n",
        "\n",
        "        # Save coordinates every 500 iterations\n",
        "        if count%500==0:\n",
        "            with open('data/coords'+str(count)+'.csv','w', newline='') as file:\n",
        "                csv_writer = csv.writer(file)\n",
        "                csv_writer.writerows(coords)\n",
        "\n",
        "        # To prevent the API from blocking us\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    # Save all the coordinates\n",
        "    with open('data/coordinates.csv','w', newline='') as file:\n",
        "        csv_writer = csv.writer(file)\n",
        "        csv_writer.writerow(['school','lat','lon'])\n",
        "        csv_writer.writerows(coords)\n",
        "\n",
        "\n",
        "    print(\"Done Downloading Coordinates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz0ZZ7Qb1Lt1"
      },
      "source": [
        "# Making heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8aIs9yHp0Ua"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
